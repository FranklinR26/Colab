# -*- coding: utf-8 -*-
"""conjunctiva_anemia_colab.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/101fX-0BEZyeehNyGAFm7g46Vkg1jhTjk
"""

# ============================================
# 0) Setup básico: Montar Drive + librerías
# ============================================
!pip install -U numpy==1.26.4 pandas==2.2.2 matplotlib==3.9.0 opencv-python-headless==4.10.0.84 scikit-learn==1.5.1 tensorflow==2.16.1 --quiet

import os, random, cv2, json, math, gc, itertools
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.model_selection import GroupShuffleSplit
from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, classification_report

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

from google.colab import drive
drive.mount('/content/driveNawa')

# ============================================
# 1) Rutas maestras (ajusta DRIVE_ROOT si hace falta)
# ============================================
DRIVE_ROOT = "/content/driveNawa/MyDrive/proyecto_conjuntiva"  # <- cambia si tu carpeta tiene otro nombre
CSV_PATH   = f"{DRIVE_ROOT}/metadata.csv"                  # CSV: filepath (relativo a IMG_ROOT), patient_id, hb, label
IMG_ROOT   = f"{DRIVE_ROOT}/images"                        # carpeta con imágenes

os.makedirs(f"{DRIVE_ROOT}/models", exist_ok=True)
os.makedirs(f"{DRIVE_ROOT}/logs", exist_ok=True)

# ============================================
# 2) Cargar metadatos y validar columnas
# ============================================
df = pd.read_csv(CSV_PATH)

# Normalizamos nombres esperados
expected_cols = {"filepath", "patient_id", "hb", "label"}
missing = expected_cols - set(df.columns.str.lower())
if missing:
    raise ValueError(f"El CSV debe tener columnas {expected_cols}. Faltan: {missing}")

# Estándar: aseguramos tipos
df.columns = [c.lower() for c in df.columns]
df["filepath"]   = df["filepath"].astype(str)
df["patient_id"] = df["patient_id"].astype(str)
df["label"]      = df["label"].astype(int)

# Chequeo rápido de existencia de archivos
def exists_row(row):
    return os.path.exists(os.path.join(IMG_ROOT, row["filepath"]))
df["exists"] = df.apply(exists_row, axis=1)
if not df["exists"].all():
    faltantes = df.loc[~df["exists"], "filepath"].head(20).tolist()
    raise FileNotFoundError(f"Hay imágenes faltantes (mostrando hasta 20): {faltantes}")

print(f"Total filas: {len(df)} | Pacientes únicos: {df['patient_id'].nunique()} | Positivos (1): {df['label'].sum()}")

# ============================================
# 3) Split por paciente (GroupShuffleSplit)
# ============================================
RANDOM_SEED = 123
gss = GroupShuffleSplit(n_splits=1, train_size=0.6, random_state=RANDOM_SEED)
train_idx, temp_idx = next(gss.split(df, groups=df["patient_id"]))
df_train = df.iloc[train_idx].reset_index(drop=True)
df_temp  = df.iloc[temp_idx].reset_index(drop=True)

# Validación y test 15%/15% por paciente
gss2 = GroupShuffleSplit(n_splits=1, train_size=0.5, random_state=RANDOM_SEED)
val_idx, test_idx = next(gss2.split(df_temp, groups=df_temp["patient_id"]))
df_val  = df_temp.iloc[val_idx].reset_index(drop=True)
df_test = df_temp.iloc[test_idx].reset_index(drop=True)

print("Split por paciente ->",
      f"train: {len(df_train)} ({df_train['patient_id'].nunique()} pacientes)",
      f"val:   {len(df_val)} ({df_val['patient_id'].nunique()} pacientes)",
      f"test:  {len(df_test)} ({df_test['patient_id'].nunique()} pacientes)", sep="\n")

# ============================================
# 4) Preprocesado de imagen (solo imágenes)
#    - Gray-world white balance
#    - CLAHE en canal V (HSV)
# ============================================
IMG_SIZE = (224, 224)
AUTOTUNE = tf.data.AUTOTUNE

def gray_world_balance_np(bgr):
    bgr = bgr.astype(np.float32)
    avgB, avgG, avgR = bgr.mean(axis=(0,1))
    avgGray = (avgB + avgG + avgR) / 3.0
    bgr[:,:,0] *= (avgGray / (avgB + 1e-6))
    bgr[:,:,1] *= (avgGray / (avgG + 1e-6))
    bgr[:,:,2] *= (avgGray / (avgR + 1e-6))
    return np.clip(bgr, 0, 255).astype(np.uint8)

def clahe_v_np(bgr):
    hsv = cv2.cvtColor(bgr, cv2.COLOR_BGR2HSV)
    v = hsv[:,:,2]
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    hsv[:,:,2] = clahe.apply(v)
    return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)

def load_and_preprocess_np(path):
    # path: bytes -> str
    path = path.decode("utf-8")
    bgr = cv2.imread(path, cv2.IMREAD_COLOR)
    if bgr is None:
        raise ValueError(f"No pude leer la imagen: {path}")
    # Preprocesado
    bgr = gray_world_balance_np(bgr)
    bgr = clahe_v_np(bgr)
    rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)
    rgb = cv2.resize(rgb, IMG_SIZE, interpolation=cv2.INTER_AREA)
    return rgb

def tf_preprocess(path, label):
    # path ya es absoluto; tf.numpy_function devuelve uint8
    img = tf.numpy_function(load_and_preprocess_np, [path], tf.uint8)
    img = tf.ensure_shape(img, (*IMG_SIZE, 3))
    img = tf.cast(img, tf.float32) / 255.0
    return img, tf.cast(label, tf.float32)

# ============================================
# 5) Construir tf.data pipelines
# ============================================
def build_ds(frame, batch=32, shuffle=False, augment=False):
    abs_paths = frame["filepath"].apply(lambda p: os.path.join(IMG_ROOT, p)).tolist()
    labels    = frame["label"].tolist()
    ds = tf.data.Dataset.from_tensor_slices((abs_paths, labels))
    if shuffle:
        ds = ds.shuffle(buffer_size=len(frame), seed=RANDOM_SEED, reshuffle_each_iteration=True)
    ds = ds.map(lambda p, y: (tf.convert_to_tensor(p), y))
    ds = ds.map(tf_preprocess, num_parallel_calls=AUTOTUNE)

    if augment:
        aug = keras.Sequential([
            layers.RandomFlip("horizontal"),
            layers.RandomRotation(0.05),
            layers.RandomContrast(0.1),
            layers.RandomBrightness(0.1),
        ])
        ds = ds.map(lambda x, y: (aug(x, training=True), y), num_parallel_calls=AUTOTUNE)

    ds = ds.batch(batch).prefetch(AUTOTUNE)
    return ds

BATCH = 32
train_ds = build_ds(df_train, batch=BATCH, shuffle=True, augment=True)
val_ds   = build_ds(df_val,   batch=BATCH, shuffle=False, augment=False)
test_ds  = build_ds(df_test,  batch=BATCH, shuffle=False, augment=False)

# ============================================
# 6) Modelo: EfficientNetB0 (warmup + fine-tune)
# ============================================
base = tf.keras.applications.EfficientNetB0(include_top=False, input_shape=(*IMG_SIZE, 3), pooling="avg")
base.trainable = False

inputs = keras.Input(shape=(*IMG_SIZE, 3))
x = base(inputs, training=False)
x = layers.Dropout(0.25)(x)
outputs = layers.Dense(1, activation="sigmoid")(x)
model = keras.Model(inputs, outputs)

# Class weights por desbalance
pos = df_train["label"].sum()
neg = len(df_train) - pos
class_weight = {0: 1.0, 1: (neg / (pos + 1e-6))}
print("class_weight:", class_weight)

model.compile(
    optimizer=keras.optimizers.Adam(1e-3),
    loss="binary_crossentropy",
    metrics=[keras.metrics.AUC(name="AUC"), keras.metrics.Precision(name="Precision"), keras.metrics.Recall(name="Recall")]
)

ckpt_path = f"{DRIVE_ROOT}/models/best_warmup.keras"
cbs = [
    keras.callbacks.ModelCheckpoint(ckpt_path, monitor="val_AUC", mode="max", save_best_only=True, verbose=1),
    keras.callbacks.EarlyStopping(monitor="val_AUC", mode="max", patience=6, restore_best_weights=True),
    keras.callbacks.ReduceLROnPlateau(monitor="val_AUC", mode="max", patience=3, factor=0.3, verbose=1)
]

hist = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=30,
    callbacks=cbs,
    class_weight=class_weight
)

# Fine-tune: desbloquea últimas ~50 capas
base.trainable = True
for layer in base.layers[:-50]:
    layer.trainable = False

model.compile(
    optimizer=keras.optimizers.Adam(3e-5),
    loss="binary_crossentropy",
    metrics=[keras.metrics.AUC(name="AUC"), keras.metrics.Precision(name="Precision"), keras.metrics.Recall(name="Recall")]
)

ckpt_path_ft = f"{DRIVE_ROOT}/models/best_finetune.keras"
cbs_ft = [
    keras.callbacks.ModelCheckpoint(ckpt_path_ft, monitor="val_AUC", mode="max", save_best_only=True, verbose=1),
    keras.callbacks.EarlyStopping(monitor="val_AUC", mode="max", patience=6, restore_best_weights=True),
    keras.callbacks.ReduceLROnPlateau(monitor="val_AUC", mode="max", patience=3, factor=0.3, verbose=1)
]

hist_ft = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=15,
    callbacks=cbs_ft,
    class_weight=class_weight
)
assert os.path.exists(CSV_PATH), f"CSV no encontrado: {CSV_PATH}"
assert os.path.isdir(IMG_ROOT),  f"Carpeta de imágenes no encontrada: {IMG_ROOT}"

from sklearn.metrics import (
    roc_auc_score, roc_curve,
    confusion_matrix, classification_report,
    precision_score
)

# ============================================
# 7) Evaluación en TEST + umbral por sensibilidad
# ============================================
# Recolectar probabilidades y etiquetas
y_true, y_prob = [], []
for xb, yb in test_ds:
    p = model.predict(xb, verbose=0).ravel()
    y_prob.extend(p.tolist())
    y_true.extend(yb.numpy().tolist())

y_true = np.array(y_true).astype(int)
y_prob = np.array(y_prob).astype(float)

# Calcular AUC y curva ROC
auc = roc_auc_score(y_true, y_prob)
fpr, tpr, thr = roc_curve(y_true, y_prob)

# Elegir umbral que logra ~90% sensibilidad (si existe)
target_sens = 0.90
idx = np.argmax(tpr >= target_sens)
thr_sens = thr[idx] if (idx < len(thr)) else 0.5
print(f"AUC (test): {auc:.4f} | Umbral @≈{target_sens*100:.0f}% Sens: {thr_sens:.4f}")

# Predicciones binarias con el umbral elegido
y_pred = (y_prob >= 0.5).astype(int) # Ajustar el umbral
# y_pred = (y_prob >= thr_sens).astype(int)

# Matriz de confusión
cm = confusion_matrix(y_true, y_pred)
print("Matriz de confusión @thr_sens:\n", cm)

# Precisión
precision = precision_score(y_true, y_pred)
print(f"Precisión: {precision:.4f}")

# Reporte de clasificación
print("\nReporte de clasificación:\n", classification_report(y_true, y_pred, digits=4))

import tensorflow as tf

# Guarda el modelo Keras primero
final_keras = f"{DRIVE_ROOT}/models/conjuntiva_final.keras"
model.save(final_keras)
print("Modelo guardado:", final_keras)

# Conversión a TFLite
converter = tf.lite.TFLiteConverter.from_keras_model(model)

# Si hay un problema de firma, asegúrate de que la entrada sea la correcta
converter.input_shapes = {model.input.name: [None, *IMG_SIZE, 3]}  # Ajusta el tamaño de entrada

# Convertir
tflite_model = converter.convert()

# Guardar el modelo convertido
tflite_path = f"{DRIVE_ROOT}/models/conjuntiva_float32.tflite"
with open(tflite_path, "wb") as f:
    f.write(tflite_model)

print("TFLite guardado:", tflite_path)

# ============================================
# 9) Función de inferencia para una sola imagen
# ============================================
def predict_one(abs_img_path, thr=thr_sens):
    # Devuelve probabilidad y clase con el preprocesado usado en entrenamiento
    rgb = load_and_preprocess_np(abs_img_path)  # devuelve RGB 224x224
    x = rgb.astype(np.float32) / 255.0
    p = float(model.predict(x[None,...], verbose=0)[0,0])
    return p, int(p >= thr)

# Ejemplo de uso:
# test_path = os.path.join(IMG_ROOT, df_test.iloc[0]["filepath"])
# prob, cls = predict_one(test_path)
# print("Prob(pálido):", prob, "Predicción:", cls)